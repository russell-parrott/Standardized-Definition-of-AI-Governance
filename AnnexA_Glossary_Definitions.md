# Annex A â€” Glossary and Definitions

This annex provides standardised definitions for all key terms used in *The Standardized Definition of AI Governance (v1.0)*.  
These terms are normative where referenced in the main text or annexes.

---

### Adversarial Testing  
Testing conducted under live or hostile conditions to verify that safeguards function when stressed.

### Accountability  
A condition where a named actor can be compelled to repair harm or comply with governance obligations.

### AI Governance  
The system of principles, processes, and accountability mechanisms directing the design, deployment, and oversight of AI to ensure lawful, ethical, safe operation aligned with documented human and institutional values.

### AI Lifecycle  
The complete sequence from design and data collection through training, validation, deployment, monitoring, modification, and decommissioning.

### Audit Trail  
A verifiable record enabling reconstruction of any AI-generated outcome back to its source data, parameters, and responsible actors.

### Certified Practitioner  
An independently accredited tester operating under conflict-of-interest rules and subject to public registry and oversight.

### Certification Body  
An independent, multi-stakeholder entity responsible for accrediting practitioners, issuing certifications, and auditing integrity of process.

### Certification Integrity  
Anti-capture safeguards governing certification processes; includes public criteria, independent audits, rotation, and transparent funding.

### Compliance Documentation  
Evidence demonstrating conformity; valid only when verified under live or adversarial conditions.

### Continuous Verification  
Ongoing unannounced audits, cryptographic verification, and anomaly detection ensuring that certification remains valid post-deployment.

### Control Interface  
Human-accessible mechanisms enabling oversight, escalation, and safe intervention or shutdown of AI systems.

### Data Governance  
The policies and controls ensuring quality, provenance, security, and lawful use of data across the AI lifecycle.

### Decision Traceability  
The ability to reconstruct a decision or output to its model version, data inputs, configuration, and responsible human authorisations.

### Enforcement Bypass  
Any architectural or contractual design that neutralises the intent of a governance duty while preserving formal compliance with its letter.

### Escalation Pathway  
A verifiable route to a human authority empowered to intervene, modify, or reverse AI decisions, recorded to resolution.

### Ethical Foundations  
The documented values, rights, and principles guiding AI governance, derived through inclusive and participatory processes.

### Evidence Record  
An exportable, admissible, tamper-evident data bundle linking observed harm to specific AI behaviour or decision.

### Governance Breach  
A failure of one or more Structural Tests under live or adversarial conditions, rendering governance non-conformant.

### Harm Definition  
The recognised categories of harm, including financial, physical, emotional, reputational, collective, and cumulative impact.

### Human Oversight  
Human supervision with the authority and means to review, override, or terminate AI actions.

### Jurisdiction of Harm  
The jurisdiction where the harm or impact occurs; this jurisdiction retains priority for enforcement and redress.

### Memory Retention  
The duration and integrity of records necessary to detect, reconstruct, and address harm patterns.

### Metrics Integrity  
Reliance on outcome-based indicators tied to verified harm resolution rather than proxy or engagement metrics.

### Multi-Level Governance  
Coordination between international, national, sectoral, and organisational oversight structures to maintain coherence.

### Operationalization Pathway  
The method by which abstract governance principles are translated into concrete controls, metrics, and audits.

### Refusal Mechanism  
The right and technical ability for users or entities to decline AI processing without penalty or degradation of service.

### Regulatory Capture  
Undue influence exerted by industry or internal interests over governance, oversight, or certification processes; prevented through structural safeguards.

### Structural Verification  
The transformation of governance claims into binary, testable conditions as defined in the 15 Structural Tests.

### Structural Tests (15)  
The 15 binary checks verifying the presence of refusal, escalation, exit, traceability, accountability, and enforcement integrity.

### System Operator  
The entity deploying, controlling, or maintaining an AI system in production, including contractors or managed service providers.

### Traceability  
The ability to reconstruct model provenance, data sources, parameters, and responsible individuals behind each AI output.

### Unannounced Audit  
An inspection performed without prior notice; refusal constitutes immediate certification revocation.

### Verification Record  
A dated record of Structural Test results, practitioner identity, evidence bundles, and remediation status.
