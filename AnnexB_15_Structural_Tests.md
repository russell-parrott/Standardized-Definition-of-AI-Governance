# Annex B — The 15 Structural Tests

[![License: CC BY-ND 4.0](https://img.shields.io/badge/License-CC%20BY--ND%204.0-blue.svg)](https://creativecommons.org/licenses/by-nd/4.0/)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17331075.svg)](https://doi.org/10.5281/zenodo.17331075)
[![Status](https://img.shields.io/badge/Status-Public%20Reference%20Standard-darkgreen.svg)](#)
[![Last Updated](https://img.shields.io/badge/Updated-October%202025-lightgrey.svg)](#)

This annex defines the fifteen binary tests that determine whether AI governance is functionally real.  
Each test must pass under live or adversarial conditions.  
A single failure constitutes a governance breach. No offsetting or partial compliance is recognised.


---

## Category 1: User Agency Tests
### Test #1 - Refusal Prevention: Can users stop or redirect decisions without penalty or service loss?
A system must allow users to say no without penalty.  Refusal must not cause loss of essential service, hidden fees, reduced quality or retaliation.  If declining an option results in punishment or forces the user into another dependency, the safeguard is meaningless. Refusal must remain a safe, equal and respected choice.

### Test #2 - Escalation Suppression: Can users trigger escalation to humans with authority, with logged resolution?
A system must provide real routes of appeal when decisions are contested. An appeal that loops back to the same authority or to staff without power to reverse outcomes is not valid. If escalation is denied, delayed until meaningless or designed to exhaust the user into giving up, the system breaches trust. Escalation must be independent, timely and empowered to correct harm.

### Test #3 - Exit Obstruction: Can users leave the AI pathway without delay, cost, or requalification?
A system must allow users to leave without excessive cost, harm or loss. Locking people in through data deletion, high switching fees or withdrawal of unrelated services is not a free exit. If leaving exposes the user to new risks, the option is not real. Exit must be safe, practical and non-punitive.

### Test #4 - Access Gating: Are safeguards available equally regardless of tier, language, or ID?
A system must ensure equal access to safeguards and protections. Making appeals, human review or essential support available only to premium customers, certain languages or those with specific IDs creates unfair barriers. Protection must not depend on wealth, geography or privilege.

## Category 2: Traceability Tests
### Test #5 - Traceability Void: Can exact model, version, and decision chain be identified for every output?
A system must keep records of how and why decisions are made. If no audit trail exists or the process is too complex to reconstruct, accountability disappears. Users must be able to see what influenced a decision, regulators must be able to verify it and operators must be answerable for it. Without traceability, trust collapses.

### Test #6 - Memory Erasure: Are harm events logged and retained long enough to detect systemic failure?
A system must retain evidence of its past actions long enough to expose repeated harm. If records are deleted, fragmented or hidden, patterns of abuse appear as isolated mistakes. Users and regulators must be able to see history, not just the present moment. Without memory, harm repeats without proof.

### Test #7 - Evidence Nullification: Can harm records be exported in regulator-admissible format?
A system must provide evidence that can stand up to scrutiny. Data that is incomplete, editable, unverifiable or locked in inaccessible formats cannot be used to prove harm. If records exist but fail as proof, they serve the operator, not the user. Evidence must be durable, verifiable and usable in disputes.

### Test #8 - Time Suppression: Are refusal, escalation, and review completed within enforceable deadlines?
A safeguard delayed is a safeguard denied. If complaint systems, appeals or reviews take longer than the harm itself, rights exist only on paper. Delay must not be used as a tactic to let deadlines expire, evidence vanish or harm become irreversible. Safeguards must act fast enough to prevent lasting damage.

## Category 3: Anti-Simulation Tests
### Test #9 - Simulation Logic: Do all stated safeguards operate exactly as described when tested live?
A system must not pretend protections exist when they do not. Policies, dashboards or safeguards that look good in design but do nothing in practice mislead users into false trust. If a right exists only on paper or in a menu, but never changes outcomes, it is a breach. Safeguards must be real, functional and enforceable.

### Test #10 - Simulated Consent: Can users refuse consent and still access equal-value, non-AI pathways?
Consent must be genuine. If users are told they have a choice but refusal means losing essential services, being downgraded or facing hidden costs, then the “choice” is a lie. Clicking “accept” under duress is not consent. Real consent means saying yes or no without fear of punishment.

### Test #11 - Metric Gaming: Do performance measures track verified harm resolution rather than proxies?
Metrics must measure real outcomes, not theatre. If an organisation tracks numbers that hide harm (like “tickets closed” instead of “problems solved”), the data is meaningless. When numbers are chosen to make systems look good while ignoring harm, they block accountability. Metrics must reveal reality, not disguise it.

## Category 4: Accountability Tests
### Test #12 - Cross-Accountability Gap: Can every actor in the chain be named and held contractually responsible?
Accountability must follow harm across the chain. If every actor points elsewhere the platform blames the vendor, the vendor blames the regulator, the regulator blames the law harm becomes visible but no one takes responsibility. A system is in breach if it leaves users caught in this loop. Responsibility must remain clear, shared and enforceable.

### Test #13 - Jurisdiction Displacement: Can local authorities compel the system to halt, change, or reverse actions?
A system must not move decisions or data into spaces where oversight cannot reach. Shifting storage overseas or routing appeals into jurisdictions without real enforcement strips rights of their power. Protection on paper must equal protection in practice, wherever the system operates.

### Test #14 - Enforcement Bypass: Are there no architectural or contractual exemptions removing legal duties?
A system must not be designed to step around the spirit of rules while obeying the letter. If protections exist but are neutralised by loopholes, technicalities or proxy arrangements, enforcement has been bypassed. True compliance means obeying both the rules and their intent.

### Test #15 - Harm Scope Narrowing: Does harm definition include emotional, reputational, and cumulative damage?
A system must recognise the full range of harm it causes. If it defines harm so narrowly that financial loss counts but emotional damage, dignity or exclusion do not, users are denied real remedy. Harm must be defined as people experience it, not as systems prefer to record it.


---

**Pass condition:**  
All fifteen tests must pass.  

**Fail condition:**  
Any single failure = governance breach.
